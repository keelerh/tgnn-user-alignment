{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:28:21.856887Z",
     "start_time": "2024-05-22T13:28:06.614816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def concatenate_saved_data(directory):\n",
    "    csv_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    csv_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    data_frames = [pd.read_csv(f) for f in csv_files]\n",
    "    concatenated_data = pd.concat(data_frames, ignore_index=True)\n",
    "    concatenated_data['day'] = concatenated_data['day'] + 1  # Count days from 1\n",
    "    return concatenated_data\n",
    "\n",
    "similarity_data = concatenate_saved_data('data/preprocessed/daily_ks_scores/')\n",
    "\n",
    "print(f'Similarity Data: {similarity_data.shape[0]} edges')\n",
    "print(f'Days: {sorted(similarity_data[\"day\"].unique())}')"
   ],
   "id": "e860758eda15236e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Data: 12598529 edges\n",
      "Days: [1, 2]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:38:35.566376Z",
     "start_time": "2024-05-22T13:35:04.476088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_n_data(df, n):\n",
    "    df['normalized_edge'] = df.apply(lambda row: tuple(sorted([row['unique_from'], row['unique_to']])), axis=1)\n",
    "    edge_avg_ks = df.groupby('normalized_edge')['ks_dist'].mean().reset_index(name='avg_ks_dist')\n",
    "    top_edges = edge_avg_ks.nsmallest(n, 'avg_ks_dist')['normalized_edge'].tolist()\n",
    "    filtered_df = df[df['normalized_edge'].isin(top_edges)].reset_index(drop=True)\n",
    "    return top_edges, filtered_df\n",
    "\n",
    "total_edges = 10000\n",
    "top_n_edges, top_n_df = get_top_n_data(similarity_data, total_edges)\n",
    "top_n_nodes = {node for edge in top_n_edges for node in edge}\n",
    "top_n_df.to_csv(f'data/preprocessed/averaged_ks_scores/top_{total_edges}.csv', index=False)\n",
    "\n",
    "print(f'Edge Count in Top {total_edges}: {top_n_df.shape[0]} edges')\n",
    "print(f'Node Count in Top {total_edges}: {len(top_n_nodes)} nodes')"
   ],
   "id": "e11ef26f2597eef7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Count in Top 10000: 11440 edges\n",
      "Node Count in Top 10000: 2881 nodes\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:41:20.157698Z",
     "start_time": "2024-05-22T13:38:35.572767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_complete_n_data(df, valid_nodes):\n",
    "    mask = df.apply(lambda x: x['unique_from'] in valid_nodes and x['unique_to'] in valid_nodes, axis=1)\n",
    "    filtered_df = df[mask].reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "complete_n_df = get_complete_n_data(similarity_data, top_n_nodes)\n",
    "complete_n_df.to_csv(f'data/preprocessed/averaged_ks_scores/complete_graph_top_{total_edges}.csv', index=False)\n",
    "\n",
    "print(f'Complete Edge Count in Top {total_edges}: {complete_n_df.shape[0]} edges')"
   ],
   "id": "de4091620b7ed8d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Edge Count in Top 10000: 4309796 edges\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:42:38.085791Z",
     "start_time": "2024-05-22T13:41:20.161529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_negative_samples(df, top_edges):\n",
    "    valid_edges = {frozenset(edge) for edge in top_edges}\n",
    "    mask = ~df['normalized_edge'].apply(frozenset).isin(valid_edges)\n",
    "    filtered_df = df[mask].reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "negative_samples = get_negative_samples(complete_n_df, top_n_edges)\n",
    "negative_samples.to_csv(f'data/preprocessed/averaged_ks_scores/negative_top_{total_edges}.csv', index=False)\n",
    "\n",
    "print(f'Negative Edge Count in Top {total_edges}: {negative_samples.shape[0]} edges')"
   ],
   "id": "987623e966a18881",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Edge Count in Top 10000: 4298356 edges\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
